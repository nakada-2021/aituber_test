FROM python:3.10-slim

RUN apt-get update && apt-get install -y build-essential cmake git wget && rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir llama-cpp-python==0.2.24 uvicorn anyio starlette fastapi pydantic_settings sse_starlette starlette_context

EXPOSE 5000

CMD ["python3", "-m", "llama_cpp.server", "--model", "/models/mistral-7b-instruct-v0.2.Q2_K.gguf", "--host", "0.0.0.0", "--port", "5000", "--n_gpu_layers", "0"] 